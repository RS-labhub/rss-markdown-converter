I've been exploring some tools that are making waves in the AI development space, and I wanted to share these:

â€¢ Kiro: If you struggled to keep up with your agent workflows, Kiro brings a spec-first philosophy (something I write a little about at the AI Native Dev), helping you structure your requirements and design from the start. 

They're back on their waitlist: kiro.dev

â€¢ Vibetunnel: Fun tool to manage multiple Claude sessions. This orchestration shell lets you handle multiple sessions and scale your tools efficiently. 

â€¢ Claude Code Usage Monitor: Every token counts, and keeping track of your costs in real-time to never get surprised by development expenses. Perfect for watching your budget while scaling your development.

What tools are you using in your AI development stack?

---

GitHub's MCP Server: ğ˜ğ¨ğ® ğœğšğ§ ğ§ğ¨ğ° ğ­ğšğ¥ğ¤ ğ­ğ¨ ğ²ğ¨ğ®ğ« ğ«ğğ©ğ¨ğ¬.

Instead of flipping between tabs, you can ask Copilot to "list open PRs touching the payment module" and get an answer on the spot.

Under the hood sits a new Go-based MCP server, the first official bridge between agents and GitHub's own APIs.

Key touches:
â€¢ get_me for plain-language queries.
â€¢ Custom tool descriptions to limit what an agent touches.
â€¢ Native support in VS Code.

The pattern feels familiar: more context for the AI, fewer detours for the developer, with a manual review as the last step.

You can find the full news with what happened, how the community is responding, and how the folks at the AI Native Dev are thinking about it: 
ainativedev.co/art

#AINativeDevelopment #MCP #GitHub #SoftwareEngineering

---

GitHub Unveils Copilot Coding Agent at Build 2025

Ask directly on GitHub, "Refactor this query into its own class," and it creates a branch, drafts a pull request, then waits for your review (CI checks and branch rules still in place).

Early testers note it shines on low-level chores, letting humans stay on design work.

A few patterns stand out:
â€¢ PR drafts run off-editor, sharing logs so you can trace every step.
â€¢ MCP hooks mean the agent can tap other tools or data without much hand holding.
â€¢ Clear acceptance criteria and solid tests seem to raise the quality of its output.

Some devs are questioning what this means for junior talent (rightly so) or secret keys slipping into commits, which suggests careful prompts and tight safeguards will matter.

You can find the full news piece, and helpful nuggets on: ainativedev.co/up9

#MCP #AINativeDevelopment #AINativeDeveloper #AIAgent #News

---

The AI Native DevCon is on today.

Take home from this virtual free conference: 
â€¢ Proven agentic workflows from leaders at Netlify, JetBrains, and Qodo
â€¢ Live walkthroughs of codeâ€‘generation and dataâ€‘pipeline tools 
â€¢ Templates that slash iteration time and ship multimodal models faster

Sessions I'm looking forward to are:
â€¢ "Vibe Coding" Through Physics Engines â€“ Nathan Peck (AWS)
â€¢ Using Fine-Tuning in Completions and Agents â€“ Nick Frolov (Refact.ai)
â€¢ Will Agentic Coders Ever Be Production-Grade? â€“ Ben Galbraith (Tessl) and Des Traynor (Intercom)
â€¢ AI for the Other 70% of Engineering â€“ Kyle Forster (RunWhen)
â€¢ From Completions to Agentic Flows â€“ Anton Arhipov (JetBrains)
â€¢ Refactor Legacy Code With AI â€“ Scott Wierschem (Keep Calm & Refactor)
â€¢ From Vibe Coding to AI Native Dev as a Craft â€“ Guy Podjarny (Tessl)

This is a conference made by AI explorers, for AI explorers. 

Share it with your relevant network.

â° 4 PM UK time (11 AM Eastern)

---

Windsurf just made Cursor look expensive

We are in a free-tier war for AI coding IDE tools, including incumbents like GitHub Copilot, Cursor, Windsurf and more. 

Windsurf is providing GPT 4.1 (OpenAI's best coding model) with 5 times more free credits, as well as unlimited completions â€”something the competition doesn't do just yet. If you are an AI explorer, a developer or a junior developer, this is an interesting opportunity to play around with Windsurf. 

More importantly, Openai decided to acquire Windsurf. 

â€¢ Maybe Windsurf gets access to cheaper or better models? 
â€¢ Will it be better to develop software using this IDE? 
â€¢ Should you commit to Windsurf already? 

Keeping up with this space is challengingâ€”upskilling is even more so. 

This is why our team (Sam Hepburn, Simon Maple, Patrick Debois, Dion Almaer) is organising a free virtual 1-day event on May 13th:

â€¢ Proven agentic workflows from Netlify, JetBrains, Qodo and more
â€¢ Live walkthroughs of code generation
â€¢ Templates that slash iteration time and ship multimodal models faster

AI NativeDevCon is a conference ğ›ğ®ğ¢ğ¥ğ­ ğ›ğ² ğ€ğˆ ğğ±ğ©ğ¥ğ¨ğ«ğğ«ğ¬, ğŸğ¨ğ« ğ€ğˆ ğğ±ğ©ğ¥ğ¨ğ«ğğ«ğ¬. 

Know of folks who would be interested? Click on the "Send" button and share it with them :) 

#AiNews #AITools #AINativeDevelopment #Conference

---

Lovable flipped the switch on 2.0. But is it the Visual Basic of the AI era?

ğ–ğ¡ğšğ­'ğ¬ ğ§ğğ°:
â€¢ Chat Mode Agent hunts files, queries DBs, and debugs on cue
â€¢ Real-time Multiplayer for better collabs (pairs on Pro, squadrons on Teams)
â€¢ Instant deploy with custom domains baked in (no more DNS set ups!)
â€¢ Increased code security, plus a freer-range Dev Mode

That said, early Reddit threads are flagging concerns (mostly around code quality) with some wondering if Lovable might've traded performance for cost savings.

Zooming out, it's part of a bigger pattern: each wave of abstraction in tech history (think assembly -> Python -> serverless) opens the door to more builders. 

Lovable's abstraction and optional control is a familiar trend in dev evolution, and one that's set to accelerate with AI-native platforms.

For anyone curious about fast prototyping or exploring agent workflows, Lovable 2.0 looks like it's worth a spin (but with eyes open!).

#AINews #AITools #AINativeDevelopment

---

It seems Windsurf is quietly resetting what "free" means for an AI IDE.

The refreshed plan gives room to tinker without opening the wallet.

â€¢ ~100 GPT-4.1 / o4-mini prompts a month (25 credits)
â€¢ Unlimited Cascade + tab completions
â€¢ Live preview and one app deploy per day

All of that sits behind a single prompt-meter, so usage stays visible even when the agent branches out.

For students and cost-watching devs, it looks like a neat sandbox for training and experimenting.

The offer also nudges Copilot and Cursor to raise the bar or watch users wander.

OpenAI's acquisition adds a twist. Could the price of experimentation drop even further? Exclusive access to models? 

Either way, keeping Windsurf in your rotation seems like a low-risk hedge while the free-tier contest unfolds.

#AINews #AITools #AINativeDevelopment

---

GPT 4.1 exposes frustrations in AI native developmentâ€”despite the hype around its release.

Why? â¬‡ï¸

Benchmarks are supposed to help, but right now, they're causing confusion. 

GPT-4.1 might outperform its predecessors on SWE-bench but stumble elsewhere (especially in front of Gemini and Claude).

It's a reminder: benchmarks aren't the full story; real-world applicability matters more.

Developers are also tired of juggling fragmented model features and inconsistent APIs.

ğ“ğ¡ğ ğ€ğˆ ğğğ¯ğğ¥ğ¨ğ©ğ¦ğğ§ğ­ ğ°ğ¨ğ«ğ¥ğ ğŸğğğ¥ğ¬ ğš ğ›ğ¢ğ­ ğ¥ğ¢ğ¤ğ ğğšğ«ğ¥ğ² ğ°ğğ› ğğğ¯ğğ¥ğ¨ğ©ğ¦ğğ§ğ­, ğ°ğ¡ğğ«ğ ğğ¯ğğ«ğ² ğ›ğ«ğ¨ğ°ğ¬ğğ« ğ¡ğšğ ğ¢ğ­ğ¬ ğ¨ğ°ğ§ ğªğ®ğ¢ğ«ğ¤ğ¬ ğšğ§ğ ğœğ®ğ¬ğ­ğ¨ğ¦ğ¢ğ¬ğšğ­ğ¢ğ¨ğ§ ğ§ğğğğ¬.

What devs really want is simplicityâ€”abstraction layers that handle multi-model complexities for them.

It's not just about the "latest and greatest" model; it's about practical integration and cost-effective performance.

The future is moving from manual model picking toward intelligent, automatic infrastructure.

Less guesswork, more building.

If you're feeling the "model maze" frustration, you're not alone.

---
